{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data frame, drop the unnecessary index row & transpose it so rows are loci and columns are individuals.\n",
    "df = pd.read_parquet(\"~/Documents/UMontana/Research/YNP/AHQsd/AHQsd_analyses/AHQsd_genotypes_filt.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label by what linkage group the loci belong to\n",
    "tmpDF = pd.DataFrame(columns=['chr','site'])\n",
    "tmpDF[['chr','site']] = df['index'].str.split('_', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['chr'] = tmpDF['chr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['site'] = tmpDF['site']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split them\n",
    "for chromo in range(1,15):\n",
    "    lg_chromo = df[df.chr == str(chromo)]\n",
    "    lg_chromo.to_csv(f'data/lg_chromo_{chromo}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_name_indivs(ds):\n",
    "    return ds.columns.to_list()[2:323] \n",
    "\n",
    "def create_bins(subset_ds):\n",
    "    # create bins of 18 SNPs each in each linkage group\n",
    "    bins = [i for i in np.arange(subset_ds.index.min(), subset_ds.index.max(), 25)] + [np.inf]\n",
    "    return bins\n",
    "\n",
    "def create_stats_template(ds, chromo_number):\n",
    "    # create dataframes for the loop to write to. \n",
    "    return pd.DataFrame(columns=[\"indv_name\",\"count\",\"mean\",f\"num_of_nans_chr{chromo_number}\"])\n",
    "\n",
    "def cut_by_bins(subset_ds, bins):\n",
    "    return pd.cut(subset_ds.index,bins=bins)\n",
    "\n",
    "def create_stats_dataframe(small_list, ds, bins, chromo_number):\n",
    "    stats_dataframe = create_stats_template(ds, chromo_number)\n",
    "    chromo_number = ds['chr'].iloc[0]\n",
    "    for col in small_list:\n",
    "        mdf = ds[['index',col]]\n",
    "        grouped_df = mdf.groupby(bins)[col].agg(['mean','count'])\n",
    "        grouped_df[f\"num_of_nans_chr{chromo_number}\"] = 25 - grouped_df[\"count\"]\n",
    "        grouped_df[\"indv_name\"] = col\n",
    "        stats_dataframe  = stats_dataframe.append(grouped_df)\n",
    "    return stats_dataframe\n",
    "\n",
    "def remove_high_NaNs(stats_dataframe, chromo_number):\n",
    "    stats_dataframe.loc[stats_dataframe[f\"num_of_nans_chr{chromo_number}\"] > 17, 'mean'] = np.nan\n",
    "    return stats_dataframe\n",
    "\n",
    "def narrow(filt_stats_dataframe): \n",
    "    filt_stats_narrow = filt_stats_dataframe[['indv_name', 'mean']]\n",
    "    filt_stats_narrow['bin'] = filt_stats_narrow.index\n",
    "    filt_stats_wide = filt_stats_narrow.pivot_table(index='bin', columns='indv_name', values='mean', aggfunc='first', dropna=False)\n",
    "    return filt_stats_wide\n",
    "\n",
    "#def cleanup_cols_names(df):\n",
    "    #df.columns = df.columns.str.split('processed/').str[1].tolist()   \n",
    "    #return df\n",
    "\n",
    "def create_bin_template():\n",
    "    col_names = ['level_0', 'first','last']\n",
    "    return pd.DataFrame(columns=col_names)\n",
    "\n",
    "def create_append_template():\n",
    "    col_names = df.columns[2:323]\n",
    "    return pd.DataFrame(columns=col_names)\n",
    "\n",
    "def convert_to_genotypes(template_df):\n",
    "    choiceList = ['BB', 'AA', 'AB']\n",
    "    all_indvs = template_df.columns\n",
    "    for i in all_indvs:\n",
    "        condList = [(template_df[i] > 1.5), (template_df[i] < .5), ((template_df[i] < 1.5) & (template_df[i] > .5))]\n",
    "        template_df[i] = np.select(condList, choiceList)\n",
    "    for i in template_df.columns:\n",
    "        template_df[i].replace('0',np.nan,inplace=True)\n",
    "    return template_df\n",
    "\n",
    "def rename_SNP_bins(ds):\n",
    "    bin_rename = pd.DataFrame(ds['index'].groupby(cut_bins).agg(['first', 'last']).stack())\n",
    "    bin_rename = bin_rename.reset_index()\n",
    "    bin_rename = bin_rename.pivot_table(index='level_0', columns='level_1', values =0,aggfunc='first', dropna=False)\n",
    "    bin_rename = bin_rename.reset_index()\n",
    "    return bin_rename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/lg_chromo_9.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-151-6d0639602b8f>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filt_stats_narrow['bin'] = filt_stats_narrow.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/lg_chromo_8.csv\n",
      "data/lg_chromo_5.csv\n",
      "data/lg_chromo_14.csv\n",
      "data/lg_chromo_4.csv\n",
      "data/lg_chromo_6.csv\n",
      "data/lg_chromo_7.csv\n",
      "data/lg_chromo_3.csv\n",
      "data/lg_chromo_12.csv\n",
      "data/lg_chromo_13.csv\n",
      "data/lg_chromo_2.csv\n",
      "data/lg_chromo_11.csv\n",
      "data/lg_chromo_10.csv\n",
      "data/lg_chromo_1.csv\n"
     ]
    }
   ],
   "source": [
    "subset_file_list = glob.glob('data/*.csv')\n",
    "ind_list = list_name_indivs(df)\n",
    "\n",
    "template_df = create_append_template()\n",
    "bin_df = create_bin_template()\n",
    "\n",
    "for fil in subset_file_list:\n",
    "    print(fil)\n",
    "    #load subset of dataset that was subset by chromosome\n",
    "    ds = pd.read_csv(fil)\n",
    "    chromo_number = ds['chr'].iloc[0]\n",
    "    #create bins\n",
    "    bins = create_bins(ds)\n",
    "    #create empty stats template\n",
    "    stats_template_df = create_stats_template(ds, chromo_number)\n",
    "    # cut each linkage group into bins of X SNPs each.\n",
    "    cut_bins = cut_by_bins(ds, bins)\n",
    "    # start renaming SNP bins\n",
    "    SNP_bin_rename = rename_SNP_bins(ds)\n",
    "    # create dataframe of stats\n",
    "    stats_dataframe = create_stats_dataframe(ind_list, ds, cut_bins, chromo_number)\n",
    "    # remove dfs with lots of NAs \n",
    "    filt_stats_dataframe = remove_high_NaNs(stats_dataframe, chromo_number)\n",
    "    # pivot magic\n",
    "    filt_stats_wide = narrow(filt_stats_dataframe)\n",
    "    #cleanup col names\n",
    "    #clean_df = cleanup_cols_names(filt_stats_wide)\n",
    "    template_df = template_df.append(filt_stats_wide,ignore_index=True)\n",
    "    bin_df = bin_df.append(SNP_bin_rename, ignore_index=True)\n",
    "#     break\n",
    "#     cleaned_ds.to_csv('final_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label the bins by the means of their SNP positions\n",
    "\n",
    "tmpDF1 = pd.DataFrame(columns=['chr','site1', 'chr_', 'site2'])\n",
    "tmpDF1[['chr','site1']] = bin_df['first'].str.split('_', expand=True)\n",
    "tmpDF1[['chr_','site2']] = bin_df['last'].str.split('_', expand=True)\n",
    "\n",
    "tmpDF1['sum'] = pd.to_numeric(tmpDF1['site1']) + pd.to_numeric(tmpDF1['site2'])\n",
    "\n",
    "tmpDF1['mean'] = tmpDF1['sum'] / 2\n",
    "\n",
    "tmpDF1['bin_mean'] = tmpDF1['chr']+\"_\"+tmpDF1['mean'].astype(str)\n",
    "\n",
    "#add the means to the whole spreadsheet\n",
    "template_df.insert(loc=0, column='bin_mean', value=tmpDF1['bin_mean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a chr column\n",
    "template_df.insert(loc=0, column='chr', value=tmpDF1['chr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a pos column\n",
    "template_df.insert(loc=0, column='pos', value=tmpDF1['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i have figured out almost everything except how to replace the values w/AA AB BB, \n",
    "# and I know there is a way to do it without for loops but my brain can't do it right now\n",
    "template_df.to_parquet(\"AHQsd_F2_SNPs_windowed.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = pd.read_parquet(\"AHQsd_F2_SNPs_windowed.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_geno = convert_to_genotypes(td.iloc[:, 3:324])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_geno.insert(loc=0, column='bin_mean', value=td['bin_mean'])\n",
    "td_geno.insert(loc=0, column='chr', value=td['chr'])\n",
    "td_geno.insert(loc=0, column='pos', value=td['pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_geno.to_parquet(\"AHQsd_F2_genotypes_windowed.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
